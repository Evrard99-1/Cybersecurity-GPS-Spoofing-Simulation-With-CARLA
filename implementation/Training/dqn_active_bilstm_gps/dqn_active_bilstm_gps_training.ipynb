{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ==== CONFIG ====\n",
    "CSV_PATH = '/content/drive/MyDrive/thesis/combined_data_Auto_pilot.csv'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SENSOR_SIZE = 10                # accel(3), gyro(3), speed, steering, throttle, brake\n",
    "EPISODES = 100\n",
    "GAMMA = 0.95\n",
    "LR = 1e-4\n",
    "MEMORY_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "SEQ_LENGTH = 5                  # temporal sequence length\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.995\n",
    "TARGET_UPDATE_FREQ = 10         # episodes\n",
    "\n",
    "def load_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "data = load_data(CSV_PATH)\n",
    "\n",
    "# Active-learning pseudo-labeling via clustering GPS coords\n",
    "def train_kmeans(data):\n",
    "    coords = data[['latitude','longitude']].values\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42).fit(coords)\n",
    "    labels = kmeans.labels_\n",
    "    mapping = {}\n",
    "    for c in np.unique(labels):\n",
    "        idxs = np.where(labels == c)[0]\n",
    "        majority = data.iloc[idxs]['label'].mode()[0]\n",
    "        mapping[c] = 1 if majority == 'spoofed' else 0\n",
    "    return kmeans, mapping\n",
    "\n",
    "kmeans, cluster_to_label = train_kmeans(data)\n",
    "\n",
    "def pseudo_label(idx):\n",
    "    coord = data.iloc[idx][['latitude','longitude']].values.reshape(1,-1)\n",
    "    cluster = kmeans.predict(coord)[0]\n",
    "    return cluster_to_label[cluster]\n",
    "\n",
    "# Build sequential sensor-state loader\n",
    "\n",
    "def load_sequence(idx):\n",
    "    seq = []\n",
    "    for offset in range(SEQ_LENGTH):\n",
    "        i = max(idx - offset, 0)\n",
    "        row = data.iloc[i]\n",
    "        sensor = row[['accel_x','accel_y','accel_z',\n",
    "                      'gyro_x','gyro_y','gyro_z',\n",
    "                      'speed','steering_angle','throttle','brake']].values.astype(np.float32)\n",
    "        seq.insert(0, sensor)\n",
    "    return torch.tensor(np.stack(seq, axis=0))  # [SEQ_LENGTH, SENSOR_SIZE]\n",
    "\n",
    "# BiLSTM-DQN model using only sensor inputs\n",
    "class BiLSTM_DQN(nn.Module):\n",
    "    def __init__(self, sensor_size, action_space):\n",
    "        super().__init__()\n",
    "        self.sensor_fc = nn.Sequential(\n",
    "            nn.Linear(sensor_size, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm = nn.LSTM(64, 128, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, action_space)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, T, sensor_size]\n",
    "        B, T, _ = x.shape\n",
    "        flat = x.view(B*T, -1)\n",
    "        emb = self.sensor_fc(flat)            # [B*T,64]\n",
    "        seq = emb.view(B, T, -1)              # [B, T,64]\n",
    "        out, _ = self.lstm(seq)               # [B, T,256]\n",
    "        return self.head(out[:, -1, :])       # [B, action_space]\n",
    "\n",
    "# Agent and networks\n",
    "action_space = 3  # 0=query,1=trust,2=replace\n",
    "online = BiLSTM_DQN(SENSOR_SIZE, action_space).to(DEVICE)\n",
    "target = BiLSTM_DQN(SENSOR_SIZE, action_space).to(DEVICE)\n",
    "target.load_state_dict(online.state_dict())\n",
    "optimizer = optim.Adam(online.parameters(), lr=LR)\n",
    "memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "epsilon = EPSILON_START\n",
    "\n",
    "def select_action(state):\n",
    "    global epsilon\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, action_space-1)\n",
    "    with torch.no_grad():\n",
    "        q = online(state.unsqueeze(0).to(DEVICE)).cpu().numpy().flatten()\n",
    "    top2 = np.partition(q, -2)[-2:]\n",
    "    if abs(top2[1] - top2[0]) < 0.1:\n",
    "        return 0\n",
    "    return int(np.argmax(q))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def replay():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    batch = random.sample(memory, BATCH_SIZE)\n",
    "    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "    s = torch.stack(states).to(DEVICE)\n",
    "    n = torch.stack(next_states).to(DEVICE)\n",
    "    a = torch.tensor(actions, device=DEVICE)\n",
    "    r = torch.tensor(rewards, device=DEVICE)\n",
    "    d = torch.tensor(dones, device=DEVICE)\n",
    "\n",
    "    q_vals = online(s).gather(1, a.unsqueeze(1)).squeeze()\n",
    "    with torch.no_grad():\n",
    "        next_q = target(n).max(1)[0]\n",
    "    tgt = r + GAMMA * next_q * (~d)\n",
    "    loss = loss_fn(q_vals, tgt)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "print(\"ðŸŽ® Training Active DQN with BiLSTM for GPS spoofing...\")\n",
    "for ep in range(1, EPISODES+1):\n",
    "    total_reward = 0\n",
    "    for idx in range(SEQ_LENGTH, len(data)-1):\n",
    "        state = load_sequence(idx)\n",
    "        next_state = load_sequence(idx+1)\n",
    "        true_label = 1 if data.iloc[idx]['label']=='spoofed' else 0\n",
    "\n",
    "        action = select_action(state)\n",
    "        if action == 0:\n",
    "            # query expert -> pseudo-label\n",
    "            _ = pseudo_label(idx)\n",
    "            reward = 0\n",
    "            done = False\n",
    "        else:\n",
    "            correct = (action==2 and true_label==1) or (action==1 and true_label==0)\n",
    "            reward = 1 if correct else -1\n",
    "            done = (idx == len(data)-2)\n",
    "            total_reward += reward\n",
    "\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        replay()\n",
    "\n",
    "    epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "    if ep % TARGET_UPDATE_FREQ == 0:\n",
    "        target.load_state_dict(online.state_dict())\n",
    "    print(f\"Episode {ep}/{EPISODES} - Total Reward: {total_reward}\")\n",
    "\n",
    "# Save model\n",
    "output_path = '/content/drive/MyDrive/thesis/dqn_active_bilstm_gps.pth'\n",
    "torch.save(online.state_dict(), output_path)\n",
    "print(f\"âœ… Model saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
